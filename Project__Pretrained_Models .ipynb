{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rALdvBem-PvT",
        "outputId": "ea9343fc-0e61-410f-9185-9d024cb4d477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "Ir1AW5APhFxi",
        "outputId": "736f5748-879e-40d7-930c-6d0d5be8850d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c199b1e0-8960-4e4b-8310-8fb22e5c6d60\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c199b1e0-8960-4e4b-8310-8fb22e5c6d60\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jr8p5d3_S1M"
      },
      "outputs": [],
      "source": [
        "mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qms21CnI_UqS"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCJVxCt3_WVV"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoDBkRWh_exs",
        "outputId": "4606ce62-b656-411b-da37-3aa7dcad980e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading skin-cancer9-classesisic.zip to /content\n",
            "100% 786M/786M [00:35<00:00, 24.4MB/s]\n",
            "100% 786M/786M [00:35<00:00, 23.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download nodoubttome/skin-cancer9-classesisic --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izRiXk_F_j4q",
        "outputId": "d33a9ac9-62a9-4d11-af16-6313e3505dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modules loaded\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from IPython.display import YouTubeVideo\n",
        "import sys\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "pd.set_option('display.max_columns', None)  # or 1000\n",
        "pd.set_option('display.max_rows', None)  # or 1000\n",
        "pd.set_option('display.max_colwidth', None)  # or 199\n",
        "print ('Modules loaded')\n",
        "import pathlib\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "import random\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /kaggle/working/data/"
      ],
      "metadata": {
        "id": "2JtE_-ediBWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_train = pathlib.Path(\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\n",
        "data_dir_test = pathlib.Path(\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Test\")"
      ],
      "metadata": {
        "id": "3lUtRh_qiDQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTAHmQzViYyv",
        "outputId": "ab72e8bd-a01c-4f30-f48b-f14ceb9f69ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2287\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -name \".ipynb_checkpoints\" -type d -exec rm -rf {} +"
      ],
      "metadata": {
        "id": "RbVqB6vMiduV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "rnd_seed = 123\n",
        "IMG_INPUT_SHAPE  = (180, 180, 3)\n",
        "random.seed(rnd_seed)"
      ],
      "metadata": {
        "id": "CYsiVexuitLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-IIJn98imWJ",
        "outputId": "f6c29a61-7543-4f0d-c7ad-0062d161239b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2287 files belonging to 10 classes.\n",
            "Using 1830 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNTrwYhKioAh",
        "outputId": "1a30f622-8be8-463f-be24-8b0e249b37c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2287 files belonging to 10 classes.\n",
            "Using 457 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_test,\n",
        "  validation_split=0.9,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv8GhrVAipyh",
        "outputId": "f7e4bf17-8490-4634-8fe7-4fa48e2dd847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 128 files belonging to 10 classes.\n",
            "Using 115 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9zyNzw7igUe",
        "outputId": "4ba523f2-c0fe-40f8-ba01-60344b90eefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Non-Skin Cancer', 'actinic keratosis', 'basal cell carcinoma', 'dermatofibroma', 'melanoma', 'nevus', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Augmentor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUz2F9vMi7bW",
        "outputId": "4bada62f-b222-493e-e2c4-1d7efa16e955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.65.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_training_dataset = '/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/'\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i, output_directory='/kaggle/working/data/'+i+'/output/')\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(1000) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKtTJUBfixgh",
        "outputId": "a1a6e5b5-01a1-4daa-d340-7db324c42533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 48 image(s) found.\n",
            "Output directory set to /kaggle/working/data/Non-Skin Cancer/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=411x482 at 0x7F919C33B940>: 100%|██████████| 1000/1000 [01:17<00:00, 12.85 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 114 image(s) found.\n",
            "Output directory set to /kaggle/working/data/actinic keratosis/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F923023B400>: 100%|██████████| 1000/1000 [00:37<00:00, 26.57 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 376 image(s) found.\n",
            "Output directory set to /kaggle/working/data/basal cell carcinoma/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F919C3AF850>: 100%|██████████| 1000/1000 [00:41<00:00, 24.26 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 95 image(s) found.\n",
            "Output directory set to /kaggle/working/data/dermatofibroma/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F91A25F0D00>: 100%|██████████| 1000/1000 [00:37<00:00, 26.79 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 438 image(s) found.\n",
            "Output directory set to /kaggle/working/data/melanoma/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=1024x768 at 0x7F919C538760>: 100%|██████████| 1000/1000 [02:58<00:00,  5.59 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 357 image(s) found.\n",
            "Output directory set to /kaggle/working/data/nevus/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7F919C4C89D0>: 100%|██████████| 1000/1000 [02:49<00:00,  5.90 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 462 image(s) found.\n",
            "Output directory set to /kaggle/working/data/pigmented benign keratosis/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F91A1E9FF40>: 100%|██████████| 1000/1000 [00:37<00:00, 26.77 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 77 image(s) found.\n",
            "Output directory set to /kaggle/working/data/seborrheic keratosis/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=1024x768 at 0x7F919C5C74F0>: 100%|██████████| 1000/1000 [01:26<00:00, 11.55 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 181 image(s) found.\n",
            "Output directory set to /kaggle/working/data/squamous cell carcinoma/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=600x450 at 0x7F923023B400>: 100%|██████████| 1000/1000 [00:37<00:00, 26.82 Samples/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 139 image(s) found.\n",
            "Output directory set to /kaggle/working/data/vascular lesion/output/."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450 at 0x7F919C5F2F80>: 100%|██████████| 1000/1000 [00:36<00:00, 27.45 Samples/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = pathlib.Path('/kaggle/working/data/')\n",
        "image_count_train = len(list(output_dir.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZkaQmOklr3",
        "outputId": "1f5c50d6-3bdb-4e81-e094-a312b60edba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSURBJXX0wPk",
        "outputId": "2e2eb048-2bd9-4acf-e8d7-09ea4136e8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 10 classes.\n",
            "Using 8000 files for training.\n",
            "Found 10000 files belonging to 10 classes.\n",
            "Using 2000 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  output_dir,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  output_dir,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plqJoY3Y0zRG"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_INPUT_SHAPE=(256,256,3)"
      ],
      "metadata": {
        "id": "uZZGzGcIm7Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StyRZpWz03jk"
      },
      "outputs": [],
      "source": [
        "def get_model(tf_model):\n",
        "    model = None\n",
        "    if tf_model == \"VGG16\":\n",
        "        model = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_tensor = tf.keras.Input(shape=IMG_INPUT_SHAPE))\n",
        "    elif tf_model == \"ResNet50\":\n",
        "        model = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_tensor = tf.keras.Input(shape=IMG_INPUT_SHAPE))\n",
        "    elif tf_model == \"MobileNetV2\":\n",
        "        model = tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\", input_tensor = tf.keras.Input(shape=IMG_INPUT_SHAPE))\n",
        "    else:\n",
        "        raise Exception('SUNXYZ', 'Model unknown')\n",
        "    return_model = tf.keras.models.Sequential()\n",
        "    return_model.add(model)\n",
        "    return_model.add(tf.keras.layers.Flatten())\n",
        "    return_model.add(tf.keras.layers.Dense(512))\n",
        "    return_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    return_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    return_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    return return_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqpRmwr307IV"
      },
      "outputs": [],
      "source": [
        "BASIC_MODEL = tf.keras.models.Sequential()\n",
        "BASIC_MODEL.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "BASIC_MODEL.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "BASIC_MODEL.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "BASIC_MODEL.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "BASIC_MODEL.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "BASIC_MODEL.add(tf.keras.layers.Flatten())\n",
        "BASIC_MODEL.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "BASIC_MODEL.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "BASIC_MODEL.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXVICmsj0_OY"
      },
      "outputs": [],
      "source": [
        "VGG16_MODEL       = get_model(\"VGG16\")\n",
        "RESNET50_MODEL    = get_model(\"ResNet50\")\n",
        "MOBILENETv2_MODEL = get_model(\"MobileNetV2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3LXViRu1CS9",
        "outputId": "31e94da8-1dd5-47cc-cdd0-5ceff20202c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               16777728  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,640,842\n",
            "Trainable params: 31,640,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VGG16_MODEL.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTdrfAxJ1Isp",
        "outputId": "eaca56d6-e4b7-44d5-aadb-f1d005f33bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               67109376  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,845,514\n",
            "Trainable params: 90,792,394\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "RESNET50_MODEL.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h2gjKk81Mcd",
        "outputId": "a8902d5b-c48c-4fa3-9c7f-31d9cc67024a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 8, 8, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 81920)             0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               41943552  \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,349,962\n",
            "Trainable params: 44,315,850\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MOBILENETv2_MODEL.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgB5ke7I1PEf"
      },
      "outputs": [],
      "source": [
        "def compile_and_fit(model):\n",
        "    model.compile(optimizer='adam',\n",
        "      loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data=val_ds,\n",
        "      epochs=10\n",
        "    )\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_MODEL.save('vgg16_model.h5')"
      ],
      "metadata": {
        "id": "fjSrNVgGiIdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESNET50_HISTORY = compile_and_fit(RESNET50_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbjfUD4rlTTV",
        "outputId": "434c3e81-3fda-42f0-96fa-dd4743f2d5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 181s 455ms/step - loss: 3.3531 - accuracy: 0.3235 - val_loss: 1.7693 - val_accuracy: 0.3445\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 1.4512 - accuracy: 0.4555 - val_loss: 2.3033 - val_accuracy: 0.2990\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 1.0806 - accuracy: 0.5954 - val_loss: 2.0161 - val_accuracy: 0.4205\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 0.8202 - accuracy: 0.7075 - val_loss: 3.0250 - val_accuracy: 0.3280\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 0.6795 - accuracy: 0.7551 - val_loss: 1.3614 - val_accuracy: 0.5770\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 111s 444ms/step - loss: 0.6035 - accuracy: 0.7934 - val_loss: 1.2790 - val_accuracy: 0.6295\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 109s 438ms/step - loss: 0.4474 - accuracy: 0.8361 - val_loss: 8.6815 - val_accuracy: 0.2295\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 113s 451ms/step - loss: 0.4394 - accuracy: 0.8449 - val_loss: 7.2100 - val_accuracy: 0.2320\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 111s 445ms/step - loss: 0.6076 - accuracy: 0.8095 - val_loss: 1.1262 - val_accuracy: 0.6710\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 113s 450ms/step - loss: 0.4167 - accuracy: 0.8543 - val_loss: 3.4159 - val_accuracy: 0.3835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESNET50_MODEL.save('resnet50_model.h5')"
      ],
      "metadata": {
        "id": "yorX5YjgslW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOBILENETv2_HISTORY = compile_and_fit(MOBILENETv2_MODEL)"
      ],
      "metadata": {
        "id": "VgdfqrdSqZTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c89b716-2c44-47e0-e56a-143cd06ade71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 97s 218ms/step - loss: 2.4697 - accuracy: 0.4176 - val_loss: 52.6307 - val_accuracy: 0.0950\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 45s 180ms/step - loss: 0.9711 - accuracy: 0.6302 - val_loss: 29.0336 - val_accuracy: 0.0945\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 45s 179ms/step - loss: 0.6287 - accuracy: 0.7600 - val_loss: 11.0969 - val_accuracy: 0.1440\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 45s 179ms/step - loss: 0.4599 - accuracy: 0.8329 - val_loss: 7.6990 - val_accuracy: 0.2220\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 45s 179ms/step - loss: 0.3794 - accuracy: 0.8654 - val_loss: 6.0190 - val_accuracy: 0.2725\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 45s 179ms/step - loss: 0.3570 - accuracy: 0.8740 - val_loss: 7.4211 - val_accuracy: 0.2835\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 45s 181ms/step - loss: 0.4106 - accuracy: 0.8618 - val_loss: 6.0780 - val_accuracy: 0.2855\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 45s 178ms/step - loss: 0.2722 - accuracy: 0.9020 - val_loss: 4.4934 - val_accuracy: 0.3520\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 45s 181ms/step - loss: 0.3735 - accuracy: 0.8799 - val_loss: 15.6747 - val_accuracy: 0.1895\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 0.3979 - accuracy: 0.8717 - val_loss: 19.6568 - val_accuracy: 0.1125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MOBILENETv2_MODEL.save('mobilenetv2_model.h5')"
      ],
      "metadata": {
        "id": "odeaGJpgsxnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}