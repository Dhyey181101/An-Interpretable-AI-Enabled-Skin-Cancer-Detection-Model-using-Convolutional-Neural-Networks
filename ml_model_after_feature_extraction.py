# -*- coding: utf-8 -*-
"""ML Model after feature Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cxwQxQonvCduIODRBKXPKa5upVnWoyZ2
"""

from google.colab import drive
drive.mount('/content/drive')

import pathlib
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import PIL
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.optimizers import Adam # - Works
import random
from glob import glob
import seaborn as sns
from tensorflow.keras.losses import SparseCategoricalCrossentropy
import matplotlib.pyplot as plt
import matplotlib.image as img
import warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

gpus = tf.config.experimental.list_physical_devices('GPU')
print(gpus)
try:
    tf.config.experimental.set_memory_growth = True
except Exception as ex:
    print(e)

data_dir_train = pathlib.Path("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train")
data_dir_test = pathlib.Path("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Test")
data_dir_valid=pathlib.Path("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Valid")

batch_size = 32
img_height = 180
img_width = 180
rnd_seed = 123
random.seed(rnd_seed)

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir_train,
  validation_split=0.001,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir_valid,
  validation_split=0.001,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
print(image_count_train)
image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
print(image_count_test)
image_count_test = len(list(data_dir_valid.glob('*/*.jpg')))
print(image_count_test)

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()
valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()

train_data = train_datagen.flow_from_directory("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train", target_size=(180, 180), batch_size=32, class_mode='categorical')

valid_data= valid_datagen.flow_from_directory("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Valid", target_size=(180, 180), batch_size=32, class_mode='categorical')

num_classes = 10
model = Sequential([layers.experimental.preprocessing.Rescaling \
                    (1.0/255,input_shape=(img_height,img_width,3))])

model.add(Conv2D(32, 3,padding="same",activation='relu'))
model.add(MaxPool2D())

model.add(Conv2D(64, 3,padding="same",activation='relu'))
model.add(MaxPool2D())

model.add(Conv2D(128, 3,padding="same",activation='relu'))
model.add(MaxPool2D())

model.add(Conv2D(256, 3,padding="same",activation='relu'))
model.add(MaxPool2D())

model.add(Conv2D(512, 3,padding="same",activation='relu'))
model.add(MaxPool2D())

model.add(Flatten())
model.add(Dense(1024,activation="relu"))
model.add(Dense(units=num_classes, activation= 'softmax'))

opt = Adam(lr=0.001)
model.compile(optimizer= opt,
              loss= SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

epochs = 25
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

model.save('my_model.h5')

import pandas as pd
from keras.models import Model
from keras.models import load_model

# Load your trained neural network model
model = load_model('model.h5')

# Create a new model that outputs extracted features
feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)


# Extract features for each input
features = feature_extractor.predict(train_ds)

# Save the extracted features to a CSV file
pd.DataFrame(features).to_csv('my_features.csv', index=False)

import pandas as pd

df = pd.read_csv('my_features.csv')

import tensorflow as tf

# Define the image data generator
datagen = tf.keras.preprocessing.image.ImageDataGenerator()

# Load the images and extract the labels
data = datagen.flow_from_directory("/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Train", target_size=(180, 180), batch_size=32, class_mode='categorical')

import tensorflow as tf

# Define the image data generator
datagen = tf.keras.preprocessing.image.ImageDataGenerator()

# Load the images and extract the labels
y = datagen.flow_from_directory('/content/drive/MyDrive/Skin cancer ISIC The International Skin Imaging Collaboration/Valid', target_size=(180, 180), batch_size=32, class_mode='categorical')

import pandas as pd

# Load the CSV file into a pandas DataFrame
data = pd.read_csv('dataset.csv')

# Extract the input features and target values
X = data.drop('Label', axis=1)  # assume 'target' is the name of the column with the target values
y = data['Label']

data.head()

#@title
sampling_strategy = {0: 1000, 1: 1000, 2: 1000, 3: 1000, 4: 1000, 5: 1000, 6: 1000, 7: 1000, 8: 1000, 9: 1000}

data.isnull().sum()

nulldata=data[data.isnull().any(axis=1)]
nulldata

data.drop([330])

from imblearn.over_sampling import SMOTE
sm=SMOTE(sampling_strategy=sampling_strategy, random_state=10)
oversampled_X, oversampled_Y = sm.fit_resample(data.drop('Label', axis=1), data['Label'])
data = pd.concat([pd.DataFrame(oversampled_Y), pd.DataFrame(oversampled_X)], axis=1)

data['Label'].value_counts()

from sklearn.model_selection import train_test_split # Import train_test_split function

#split dataset in features and target variable
X = data.drop('Label', axis=1)#features
Y = data['Label'] # Target variable

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1) # 80% training and 20% test

X_train.shape

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

xgb = XGBClassifier()
xgb.fit(X_train, Y_train)
print(xgb)

xgb_pred = xgb.predict(X_test)
predictions = [round(value) for value in xgb_pred]

accuracy = accuracy_score(Y_test, predictions)
print(accuracy)

